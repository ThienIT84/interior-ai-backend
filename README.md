# AI Interior Design - Backend

Backend API cho há»‡ thá»‘ng AI Interior Design sá»­ dá»¥ng FastAPI, SAM, vÃ  Stable Diffusion.

## ğŸ¯ Features

- âœ… **SAM Segmentation**: Interactive point-based object segmentation
- âœ… **Stable Diffusion Inpainting**: Remove objects and generate empty rooms
- â³ **ControlNet Generation**: Generate new interior designs (Week 3)
- â³ **AR Support**: 3D visualization endpoints (Week 4)

## ğŸ“Š Performance

| Component | Latency | VRAM | Cost |
|-----------|---------|------|------|
| SAM Segmentation | 0.2-0.5s | 1.5-2GB | $0 |
| SD Inpainting | 13-15 min | 3.5-4GB | $0 |

**Hardware**: GTX 1650 4GB VRAM

## ğŸš€ Quick Start

### 1. Activate Environment
```bash
~/miniconda3/envs/interior_ai/bin/python
```

### 2. Start Server
```bash
cd ~/interior_project/backend
~/miniconda3/envs/interior_ai/bin/python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 3. Access API
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## ğŸ“ Project Structure

```
backend/
â”œâ”€â”€ app/                          # Main application
â”‚   â”œâ”€â”€ api/v1/endpoints/         # API routes
â”‚   â”‚   â”œâ”€â”€ segmentation.py       # âœ… SAM endpoints
â”‚   â”‚   â”œâ”€â”€ inpainting.py         # âœ… Inpainting endpoints
â”‚   â”‚   â””â”€â”€ health.py             # âœ… Health check
â”‚   â”œâ”€â”€ core/                     # Business logic
â”‚   â”‚   â”œâ”€â”€ sam_segmentation.py   # âœ… SAM wrapper
â”‚   â”‚   â””â”€â”€ diffusion_inpainting.py # âœ… SD wrapper
â”‚   â”œâ”€â”€ config.py                 # Configuration
â”‚   â””â”€â”€ main.py                   # FastAPI app
â”œâ”€â”€ data/                         # Data storage
â”‚   â”œâ”€â”€ inputs/                   # Uploaded images
â”‚   â”œâ”€â”€ masks/                    # Generated masks
â”‚   â””â”€â”€ outputs/                  # Inpainting results
â”œâ”€â”€ weights/                      # Model checkpoints
â”‚   â””â”€â”€ sam_vit_b_01ec64.pth     # SAM model
â””â”€â”€ Test scripts & Documentation
```

## ğŸ”§ Setup

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (GTX 1650 4GB or better)
- Conda environment: `interior_ai`

### Installation

```bash
# 1. Install dependencies
cd backend
pip install -r requirements.txt

# 2. Download SAM weights (if not exists)
# Place sam_vit_b_01ec64.pth in weights/

# 3. Configure environment (optional)
cp .env.example .env
```

### First Run

```bash
# Start server
~/miniconda3/envs/interior_ai/bin/python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Test in another terminal
~/miniconda3/envs/interior_ai/bin/python test_inpainting_api.py
```

## ğŸ“¡ API Endpoints

### Segmentation
- `POST /api/v1/segmentation/upload` - Upload image, get image_id
- `POST /api/v1/segmentation/segment-points` - Segment with points
- `GET /api/v1/segmentation/image/{image_id}` - Get uploaded image
- `GET /api/v1/segmentation/mask-image/{mask_id}` - Get mask PNG

### Inpainting
- `POST /api/v1/inpainting/remove-object-async` - Submit inpainting job
- `GET /api/v1/inpainting/job-status/{job_id}` - Check job status
- `GET /api/v1/inpainting/result/{result_id}` - Get result image

### Health
- `GET /api/v1/health` - System health check

## ğŸ§ª Testing

```bash
# Test SAM segmentation
~/miniconda3/envs/interior_ai/bin/python test_sam_dataset.py

# Test inpainting integration
~/miniconda3/envs/interior_ai/bin/python test_inpainting_api.py

# Benchmark performance
~/miniconda3/envs/interior_ai/bin/python benchmark_sam.py

# Optimize parameters
~/miniconda3/envs/interior_ai/bin/python optimize_inpainting_strength.py
```

See [TESTING.md](TESTING.md) for detailed test guide.

## ğŸ“š Documentation

- **[DEVELOPMENT_GUIDE.md](DEVELOPMENT_GUIDE.md)** - Development workflow
- **[TESTING.md](TESTING.md)** - Testing guide
- **[TEST_INPAINTING.md](TEST_INPAINTING.md)** - Inpainting test instructions
- **[PROJECT_STATUS.md](PROJECT_STATUS.md)** - Current project status
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - System architecture
- **[COST_ANALYSIS.md](COST_ANALYSIS.md)** - Cost comparison
- **[INPAINTING_ALTERNATIVES.md](INPAINTING_ALTERNATIVES.md)** - Alternative methods

## ğŸ› ï¸ Development

### Adding New Features

1. **Core logic**: Add to `app/core/`
2. **API models**: Add to `app/models/`
3. **Endpoints**: Add to `app/api/v1/endpoints/`
4. **Register**: Update `app/api/v1/router.py`

### Code Style
- Follow PEP 8
- Use type hints
- Add docstrings
- Handle errors gracefully

## âš™ï¸ Configuration

### Optimized Parameters (GTX 1650 4GB)

**SAM:**
```python
model = "vit_b"
checkpoint = "weights/sam_vit_b_01ec64.pth"
```

**Stable Diffusion Inpainting:**
```python
model = "runwayml/stable-diffusion-inpainting"
dtype = torch.float32  # NOT fp16
steps = 50
guidance_scale = 11.0
strength = 0.99
```

## ğŸ› Troubleshooting

### Backend won't start
```bash
# Check Python version
~/miniconda3/envs/interior_ai/bin/python --version

# Check dependencies
~/miniconda3/envs/interior_ai/bin/pip list | grep -E "torch|diffusers|fastapi"
```

### Out of memory
```bash
# Check VRAM usage
nvidia-smi

# Clear CUDA cache
~/miniconda3/envs/interior_ai/bin/python -c "import torch; torch.cuda.empty_cache()"
```

### Black output from inpainting
âœ… **FIXED**: Use float32 instead of fp16 (implemented in code)

See [DEVELOPMENT_GUIDE.md](DEVELOPMENT_GUIDE.md) for more troubleshooting.

## ğŸ“ˆ Roadmap

- [x] **Week 1**: SAM segmentation + Flutter UI
- [x] **Week 2 (Day 8-9)**: Inpainting integration
- [ ] **Week 2 (Day 10-14)**: Testing & optimization
- [ ] **Week 3**: ControlNet generation
- [ ] **Week 4**: AR + finalization

See [PROJECT_STATUS.md](PROJECT_STATUS.md) for detailed progress.

## ğŸ¤ Contributing

1. Follow project structure
2. Write tests for new features
3. Update documentation
4. Test on real images

## ğŸ“ Notes

- Models load once at startup (singleton pattern)
- CORS enabled for Flutter app
- Auto-detect CUDA/CPU
- Results cached in `data/outputs/`
- Async processing for long-running tasks

## ğŸ“ Support

For issues:
1. Check documentation files
2. Review test scripts
3. Check API docs at `/docs`
4. Review code comments
